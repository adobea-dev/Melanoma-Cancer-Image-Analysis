{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beae6e0c",
   "metadata": {},
   "source": [
    "### Importing the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b01a9",
   "metadata": {},
   "source": [
    "### Reading both our train and test data & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ad20d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_dir = 'dataset'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "# Function to display sample images\n",
    "def display_samples(image_dir, label, num_samples=5):\n",
    "    folder = os.path.join(image_dir, label)\n",
    "    images = os.listdir(folder)[:num_samples]\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, img_name in enumerate(images):\n",
    "        img_path = os.path.join(folder, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{label.capitalize()} Sample {i + 1}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# Display samples from training set\n",
    "display_samples(train_dir, 'benign')\n",
    "display_samples(train_dir, 'malignant')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87ffb8b",
   "metadata": {},
   "source": [
    "Looking at these benign samples, we can already observe some challenges in the dataset;\n",
    "\n",
    "1. Variability in Skin Tone & Lighting\n",
    "\n",
    "Some images appear pinkish, while others have a neutral skin tone. This variation in color may affect model performance if not handled correctly.\n",
    "\n",
    "2. Presence of Artifacts\n",
    "\n",
    "In some images, there are hairs, scratches, and other marks that might not be related to the lesion itself. These could introduce noise into the model.\n",
    "\n",
    "3. Uneven Focus & Resolution\n",
    "\n",
    "Some images seem sharper than others, which may impact feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3295c20d",
   "metadata": {},
   "source": [
    "#### Checking resolution consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e970227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define function to check image resolutions\n",
    "def check_image_resolutions(directory):\n",
    "    widths, heights = [], []\n",
    "    \n",
    "    for label in ['benign', 'malignant']:\n",
    "        folder = os.path.join(directory, label)\n",
    "        for img_name in os.listdir(folder):\n",
    "            img_path = os.path.join(folder, img_name)\n",
    "            img = Image.open(img_path)\n",
    "            widths.append(img.width)\n",
    "            heights.append(img.height)\n",
    "    \n",
    "    return widths, heights\n",
    "\n",
    "# Get image resolutions from train dataset\n",
    "widths, heights = check_image_resolutions(train_dir)\n",
    "\n",
    "# Plot distribution of image resolutions\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.scatterplot(x=widths, y=heights, alpha=0.5)\n",
    "plt.xlabel(\"Width\")\n",
    "plt.ylabel(\"Height\")\n",
    "plt.title(\"Image Resolution Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc28778",
   "metadata": {},
   "source": [
    "The single clustered point in the scatter plot indicates that there is no significant variation in image sizes, meaning we donâ€™t need extra resizing adjustments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21186cb7",
   "metadata": {},
   "source": [
    "#### Pixel Intensity Distribution (Histogram Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa9f913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14a43083",
   "metadata": {},
   "source": [
    "Finding the distribution of benign and malignant cases helps identify potential class imbalances, which can influence model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ddbe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count images in each category\n",
    "def count_images(directory):\n",
    "    categories = ['benign', 'malignant']\n",
    "    counts = {category: len(os.listdir(os.path.join(directory, category))) for category in categories}\n",
    "    return counts\n",
    "\n",
    "# Count images in train and test sets\n",
    "train_counts = count_images(train_dir)\n",
    "test_counts = count_images(test_dir)\n",
    "\n",
    "# Display counts\n",
    "print(f\"Training Set - Benign: {train_counts['benign']}, Malignant: {train_counts['malignant']}\")\n",
    "print(f\"Testing Set - Benign: {test_counts['benign']}, Malignant: {test_counts['malignant']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c3aff",
   "metadata": {},
   "source": [
    "While the testing set is balanced, the training set exhibits a slight imbalance, with benign cases outnumbering malignant ones. Although this imbalance isn't severe, it's essential to address it to ensure robust model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98b161",
   "metadata": {},
   "source": [
    "#### Visualizing the class distribution provides a clearer picture of any imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ddb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot class distribution\n",
    "def plot_class_distribution(counts, title):\n",
    "    categories = list(counts.keys())\n",
    "    values = list(counts.values())\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(categories, values, color=['blue', 'red'])\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Plot class distribution for training and testing sets\n",
    "plot_class_distribution(train_counts, 'Training Set Class Distribution')\n",
    "plot_class_distribution(test_counts, 'Testing Set Class Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f6079",
   "metadata": {},
   "source": [
    "#### Addressing class imbalance\n",
    "To further enhance model performance and address class imbalance, consider augmenting both classes and incorporating class weights during training. These strategies collectively contribute to a more robust and generalizable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation strategies\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generator for benign class\n",
    "benign_gen = data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes=['benign'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Generator for malignant class\n",
    "malignant_gen = data_gen.flow_from_directory(\n",
    "    train_dir,\n",
    "    classes=['malignant'],\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Generators\n",
    "def combined_generator(gen1, gen2):\n",
    "    while True:\n",
    "        batch1 = gen1.next()\n",
    "        batch2 = gen2.next()\n",
    "        images = np.concatenate((batch1[0], batch2[0]), axis=0)\n",
    "        labels = np.concatenate((batch1[1], batch2[1]), axis=0)\n",
    "        yield images, labels\n",
    "\n",
    "train_generator = combined_generator(benign_gen, malignant_gen)\n",
    "\n",
    "#Adjust Class Weights\n",
    " \n",
    "#Define class labels\n",
    "class_labels = ['benign', 'malignant']\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(class_labels),\n",
    "    y=class_labels\n",
    ")\n",
    "\n",
    "# Convert to dictionary\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cddac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the class_weights dictionary to the fit or fit_generator method during model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (melanoma-env)",
   "language": "python",
   "name": "melanoma-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
